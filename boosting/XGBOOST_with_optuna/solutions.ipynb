{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBOOST for classification and Hyperparameter using Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "\n",
    "import optuna\n",
    "import xgboost as xgb\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading data\n",
    "breast_cancer = load_breast_cancer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _breast_cancer_dataset:\n",
      "\n",
      "Breast cancer wisconsin (diagnostic) dataset\n",
      "--------------------------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 569\n",
      "\n",
      "    :Number of Attributes: 30 numeric, predictive attributes and the class\n",
      "\n",
      "    :Attribute Information:\n",
      "        - radius (mean of distances from center to points on the perimeter)\n",
      "        - texture (standard deviation of gray-scale values)\n",
      "        - perimeter\n",
      "        - area\n",
      "        - smoothness (local variation in radius lengths)\n",
      "        - compactness (perimeter^2 / area - 1.0)\n",
      "        - concavity (severity of concave portions of the contour)\n",
      "        - concave points (number of concave portions of the contour)\n",
      "        - symmetry\n",
      "        - fractal dimension (\"coastline approximation\" - 1)\n",
      "\n",
      "        The mean, standard error, and \"worst\" or largest (mean of the three\n",
      "        worst/largest values) of these features were computed for each image,\n",
      "        resulting in 30 features.  For instance, field 0 is Mean Radius, field\n",
      "        10 is Radius SE, field 20 is Worst Radius.\n",
      "\n",
      "        - class:\n",
      "                - WDBC-Malignant\n",
      "                - WDBC-Benign\n",
      "\n",
      "    :Summary Statistics:\n",
      "\n",
      "    ===================================== ====== ======\n",
      "                                           Min    Max\n",
      "    ===================================== ====== ======\n",
      "    radius (mean):                        6.981  28.11\n",
      "    texture (mean):                       9.71   39.28\n",
      "    perimeter (mean):                     43.79  188.5\n",
      "    area (mean):                          143.5  2501.0\n",
      "    smoothness (mean):                    0.053  0.163\n",
      "    compactness (mean):                   0.019  0.345\n",
      "    concavity (mean):                     0.0    0.427\n",
      "    concave points (mean):                0.0    0.201\n",
      "    symmetry (mean):                      0.106  0.304\n",
      "    fractal dimension (mean):             0.05   0.097\n",
      "    radius (standard error):              0.112  2.873\n",
      "    texture (standard error):             0.36   4.885\n",
      "    perimeter (standard error):           0.757  21.98\n",
      "    area (standard error):                6.802  542.2\n",
      "    smoothness (standard error):          0.002  0.031\n",
      "    compactness (standard error):         0.002  0.135\n",
      "    concavity (standard error):           0.0    0.396\n",
      "    concave points (standard error):      0.0    0.053\n",
      "    symmetry (standard error):            0.008  0.079\n",
      "    fractal dimension (standard error):   0.001  0.03\n",
      "    radius (worst):                       7.93   36.04\n",
      "    texture (worst):                      12.02  49.54\n",
      "    perimeter (worst):                    50.41  251.2\n",
      "    area (worst):                         185.2  4254.0\n",
      "    smoothness (worst):                   0.071  0.223\n",
      "    compactness (worst):                  0.027  1.058\n",
      "    concavity (worst):                    0.0    1.252\n",
      "    concave points (worst):               0.0    0.291\n",
      "    symmetry (worst):                     0.156  0.664\n",
      "    fractal dimension (worst):            0.055  0.208\n",
      "    ===================================== ====== ======\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "    :Class Distribution: 212 - Malignant, 357 - Benign\n",
      "\n",
      "    :Creator:  Dr. William H. Wolberg, W. Nick Street, Olvi L. Mangasarian\n",
      "\n",
      "    :Donor: Nick Street\n",
      "\n",
      "    :Date: November, 1995\n",
      "\n",
      "This is a copy of UCI ML Breast Cancer Wisconsin (Diagnostic) datasets.\n",
      "https://goo.gl/U2Uwz2\n",
      "\n",
      "Features are computed from a digitized image of a fine needle\n",
      "aspirate (FNA) of a breast mass.  They describe\n",
      "characteristics of the cell nuclei present in the image.\n",
      "\n",
      "Separating plane described above was obtained using\n",
      "Multisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree\n",
      "Construction Via Linear Programming.\" Proceedings of the 4th\n",
      "Midwest Artificial Intelligence and Cognitive Science Society,\n",
      "pp. 97-101, 1992], a classification method which uses linear\n",
      "programming to construct a decision tree.  Relevant features\n",
      "were selected using an exhaustive search in the space of 1-4\n",
      "features and 1-3 separating planes.\n",
      "\n",
      "The actual linear program used to obtain the separating plane\n",
      "in the 3-dimensional space is that described in:\n",
      "[K. P. Bennett and O. L. Mangasarian: \"Robust Linear\n",
      "Programming Discrimination of Two Linearly Inseparable Sets\",\n",
      "Optimization Methods and Software 1, 1992, 23-34].\n",
      "\n",
      "This database is also available through the UW CS ftp server:\n",
      "\n",
      "ftp ftp.cs.wisc.edu\n",
      "cd math-prog/cpo-dataset/machine-learn/WDBC/\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "   - W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction \n",
      "     for breast tumor diagnosis. IS&T/SPIE 1993 International Symposium on \n",
      "     Electronic Imaging: Science and Technology, volume 1905, pages 861-870,\n",
      "     San Jose, CA, 1993.\n",
      "   - O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and \n",
      "     prognosis via linear programming. Operations Research, 43(4), pages 570-577, \n",
      "     July-August 1995.\n",
      "   - W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Machine learning techniques\n",
      "     to diagnose breast cancer from fine-needle aspirates. Cancer Letters 77 (1994) \n",
      "     163-171.\n"
     ]
    }
   ],
   "source": [
    "#Describe the dataset\n",
    "print(breast_cancer.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mean radius' 'mean texture' 'mean perimeter' 'mean area'\n",
      " 'mean smoothness' 'mean compactness' 'mean concavity'\n",
      " 'mean concave points' 'mean symmetry' 'mean fractal dimension'\n",
      " 'radius error' 'texture error' 'perimeter error' 'area error'\n",
      " 'smoothness error' 'compactness error' 'concavity error'\n",
      " 'concave points error' 'symmetry error' 'fractal dimension error'\n",
      " 'worst radius' 'worst texture' 'worst perimeter' 'worst area'\n",
      " 'worst smoothness' 'worst compactness' 'worst concavity'\n",
      " 'worst concave points' 'worst symmetry' 'worst fractal dimension']\n"
     ]
    }
   ],
   "source": [
    "#print the features of the dataset\n",
    "print(breast_cancer.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['malignant' 'benign']\n"
     ]
    }
   ],
   "source": [
    "#print the target of the dataset\n",
    "print(breast_cancer.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = breast_cancer.data\n",
    "y = breast_cancer.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape:  (455, 30)\n",
      "X_test shape:  (114, 30)\n",
      "y_train shape:  (455,)\n",
      "y_test shape:  (114,)\n"
     ]
    }
   ],
   "source": [
    "#printing the shapes of the train and test sets\n",
    "print(\"X_train shape: \", X_train.shape)\n",
    "print(\"X_test shape: \", X_test.shape)\n",
    "print(\"y_train shape: \", y_train.shape)\n",
    "print(\"y_test shape: \", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=None, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=None, ...)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fit a XGBoost Classifier with default parameters\n",
    "clf_xgb = xgb.XGBClassifier()\n",
    "clf_xgb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 2: Default XGBoost Classifier Performance:\n",
      "Accuracy: 0.96\n",
      "Precision: 0.96\n",
      "Recall: 0.97\n",
      "F1-Score: 0.97\n",
      "ROC-AUC: 0.95\n"
     ]
    }
   ],
   "source": [
    "#predict the test set\n",
    "y_pred = clf_xgb.predict(X_test)\n",
    "\n",
    "#calculate the performance metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "print(\"Task 2: Default XGBoost Classifier Performance:\")\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1-Score: {f1:.2f}\")\n",
    "print(f\"ROC-AUC: {roc_auc:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter using Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining the objective function\n",
    "\n",
    "def objective(trial):\n",
    "\n",
    "    params = {\n",
    "        \"verbosity\": 0,\n",
    "        \"objective\": \"binary:logistic\",\n",
    "        \"booster\": trial.suggest_categorical(\"booster\", [\"gbtree\", \"gblinear\", \"dart\"]),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 10),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.3),\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 10, 100, step=1),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.6, 0.9),\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.6, 0.9),\n",
    "    }\n",
    "\n",
    "    model = xgb.XGBClassifier(**params)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = sklearn.metrics.accuracy_score(y_test, y_pred)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-26 09:58:54,667] A new study created in memory with name: no-name-bf1948c5-0844-4183-ba09-98025e19ae4b\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-26 09:58:54,809] Trial 0 finished with value: 0.9473684210526315 and parameters: {'booster': 'gblinear', 'max_depth': 5, 'learning_rate': 0.03796763959479714, 'n_estimators': 66, 'subsample': 0.662155547728396, 'colsample_bytree': 0.8469826637775553}. Best is trial 0 with value: 0.9473684210526315.\n",
      "[I 2024-03-26 09:58:54,873] Trial 1 finished with value: 0.956140350877193 and parameters: {'booster': 'gbtree', 'max_depth': 10, 'learning_rate': 0.07577761789654644, 'n_estimators': 57, 'subsample': 0.6220096012186467, 'colsample_bytree': 0.7677637601899945}. Best is trial 1 with value: 0.956140350877193.\n",
      "[I 2024-03-26 09:58:54,892] Trial 2 finished with value: 0.956140350877193 and parameters: {'booster': 'dart', 'max_depth': 8, 'learning_rate': 0.27505989098900036, 'n_estimators': 11, 'subsample': 0.7480729101133056, 'colsample_bytree': 0.7277584909495364}. Best is trial 1 with value: 0.956140350877193.\n",
      "[I 2024-03-26 09:58:54,909] Trial 3 finished with value: 0.9649122807017544 and parameters: {'booster': 'gbtree', 'max_depth': 9, 'learning_rate': 0.2758621844512359, 'n_estimators': 22, 'subsample': 0.6927941468890965, 'colsample_bytree': 0.8141730599457371}. Best is trial 3 with value: 0.9649122807017544.\n",
      "[I 2024-03-26 09:58:54,915] Trial 4 finished with value: 0.9473684210526315 and parameters: {'booster': 'gblinear', 'max_depth': 8, 'learning_rate': 0.21074806687367845, 'n_estimators': 25, 'subsample': 0.8745303070330802, 'colsample_bytree': 0.700398310339678}. Best is trial 3 with value: 0.9649122807017544.\n",
      "[I 2024-03-26 09:58:54,958] Trial 5 finished with value: 0.9473684210526315 and parameters: {'booster': 'gblinear', 'max_depth': 6, 'learning_rate': 0.08838089183649056, 'n_estimators': 90, 'subsample': 0.6168403991945082, 'colsample_bytree': 0.7725902650691766}. Best is trial 3 with value: 0.9649122807017544.\n",
      "[I 2024-03-26 09:58:54,972] Trial 6 finished with value: 0.9473684210526315 and parameters: {'booster': 'gblinear', 'max_depth': 7, 'learning_rate': 0.1801356261285959, 'n_estimators': 41, 'subsample': 0.8836348660914592, 'colsample_bytree': 0.652224619657461}. Best is trial 3 with value: 0.9649122807017544.\n",
      "[I 2024-03-26 09:58:55,007] Trial 7 finished with value: 0.9649122807017544 and parameters: {'booster': 'dart', 'max_depth': 9, 'learning_rate': 0.21277134321105193, 'n_estimators': 31, 'subsample': 0.6973011595804964, 'colsample_bytree': 0.7009176894048289}. Best is trial 3 with value: 0.9649122807017544.\n",
      "[I 2024-03-26 09:58:55,218] Trial 8 finished with value: 0.9649122807017544 and parameters: {'booster': 'dart', 'max_depth': 3, 'learning_rate': 0.12206005661342303, 'n_estimators': 56, 'subsample': 0.802192456222424, 'colsample_bytree': 0.6388457870743607}. Best is trial 3 with value: 0.9649122807017544.\n",
      "[I 2024-03-26 09:58:55,232] Trial 9 finished with value: 0.956140350877193 and parameters: {'booster': 'gbtree', 'max_depth': 3, 'learning_rate': 0.06004900611627574, 'n_estimators': 28, 'subsample': 0.6456882080173909, 'colsample_bytree': 0.8884084644749106}. Best is trial 3 with value: 0.9649122807017544.\n",
      "[I 2024-03-26 09:58:55,255] Trial 10 finished with value: 0.956140350877193 and parameters: {'booster': 'gbtree', 'max_depth': 10, 'learning_rate': 0.25936499586994466, 'n_estimators': 10, 'subsample': 0.7243865212912495, 'colsample_bytree': 0.8125690141132799}. Best is trial 3 with value: 0.9649122807017544.\n",
      "[I 2024-03-26 09:58:55,315] Trial 11 finished with value: 0.9649122807017544 and parameters: {'booster': 'dart', 'max_depth': 9, 'learning_rate': 0.2937315189143034, 'n_estimators': 35, 'subsample': 0.6953478014656418, 'colsample_bytree': 0.6930341017368781}. Best is trial 3 with value: 0.9649122807017544.\n",
      "[I 2024-03-26 09:58:55,390] Trial 12 finished with value: 0.956140350877193 and parameters: {'booster': 'dart', 'max_depth': 9, 'learning_rate': 0.22703612486650276, 'n_estimators': 45, 'subsample': 0.6895116269705409, 'colsample_bytree': 0.7956176815516138}. Best is trial 3 with value: 0.9649122807017544.\n",
      "[I 2024-03-26 09:58:55,427] Trial 13 finished with value: 0.956140350877193 and parameters: {'booster': 'gbtree', 'max_depth': 8, 'learning_rate': 0.16274784835705222, 'n_estimators': 21, 'subsample': 0.710856091059475, 'colsample_bytree': 0.7371704817580915}. Best is trial 3 with value: 0.9649122807017544.\n",
      "[I 2024-03-26 09:58:55,549] Trial 14 finished with value: 0.956140350877193 and parameters: {'booster': 'dart', 'max_depth': 6, 'learning_rate': 0.2438561727157729, 'n_estimators': 72, 'subsample': 0.7805353946432696, 'colsample_bytree': 0.8278582741161079}. Best is trial 3 with value: 0.9649122807017544.\n",
      "[I 2024-03-26 09:58:55,580] Trial 15 finished with value: 0.9649122807017544 and parameters: {'booster': 'gbtree', 'max_depth': 9, 'learning_rate': 0.2945812826552734, 'n_estimators': 37, 'subsample': 0.6687352496857806, 'colsample_bytree': 0.6091223478276422}. Best is trial 3 with value: 0.9649122807017544.\n",
      "[I 2024-03-26 09:58:55,616] Trial 16 finished with value: 0.956140350877193 and parameters: {'booster': 'dart', 'max_depth': 10, 'learning_rate': 0.20103163395207274, 'n_estimators': 20, 'subsample': 0.7311154934105835, 'colsample_bytree': 0.7766977357977256}. Best is trial 3 with value: 0.9649122807017544.\n",
      "[I 2024-03-26 09:58:55,665] Trial 17 finished with value: 0.9649122807017544 and parameters: {'booster': 'gbtree', 'max_depth': 7, 'learning_rate': 0.24319095811361202, 'n_estimators': 99, 'subsample': 0.6898850636622137, 'colsample_bytree': 0.7455290729071096}. Best is trial 3 with value: 0.9649122807017544.\n",
      "[I 2024-03-26 09:58:55,699] Trial 18 finished with value: 0.9649122807017544 and parameters: {'booster': 'gbtree', 'max_depth': 5, 'learning_rate': 0.19238590643057418, 'n_estimators': 48, 'subsample': 0.6008412947740062, 'colsample_bytree': 0.8618553940356657}. Best is trial 3 with value: 0.9649122807017544.\n",
      "[I 2024-03-26 09:58:55,739] Trial 19 finished with value: 0.956140350877193 and parameters: {'booster': 'dart', 'max_depth': 9, 'learning_rate': 0.22378888564048213, 'n_estimators': 27, 'subsample': 0.6458018576880967, 'colsample_bytree': 0.8012942071809734}. Best is trial 3 with value: 0.9649122807017544.\n",
      "[I 2024-03-26 09:58:55,862] Trial 20 finished with value: 0.9649122807017544 and parameters: {'booster': 'dart', 'max_depth': 8, 'learning_rate': 0.14881625766413875, 'n_estimators': 72, 'subsample': 0.7579654041200247, 'colsample_bytree': 0.7120562289342564}. Best is trial 3 with value: 0.9649122807017544.\n",
      "[I 2024-03-26 09:58:56,077] Trial 21 finished with value: 0.9649122807017544 and parameters: {'booster': 'dart', 'max_depth': 3, 'learning_rate': 0.13319945296921368, 'n_estimators': 62, 'subsample': 0.7829614782860645, 'colsample_bytree': 0.6663439513540136}. Best is trial 3 with value: 0.9649122807017544.\n",
      "[I 2024-03-26 09:58:56,277] Trial 22 finished with value: 0.9649122807017544 and parameters: {'booster': 'dart', 'max_depth': 4, 'learning_rate': 0.2646867269686505, 'n_estimators': 51, 'subsample': 0.810759828897932, 'colsample_bytree': 0.6080642792802348}. Best is trial 3 with value: 0.9649122807017544.\n",
      "[I 2024-03-26 09:58:56,442] Trial 23 finished with value: 0.9649122807017544 and parameters: {'booster': 'dart', 'max_depth': 4, 'learning_rate': 0.11805037444828027, 'n_estimators': 33, 'subsample': 0.7053429831551719, 'colsample_bytree': 0.6574511678213109}. Best is trial 3 with value: 0.9649122807017544.\n",
      "[I 2024-03-26 09:58:56,617] Trial 24 finished with value: 0.9649122807017544 and parameters: {'booster': 'dart', 'max_depth': 7, 'learning_rate': 0.17429226251078708, 'n_estimators': 80, 'subsample': 0.8228283498431983, 'colsample_bytree': 0.6851877345286927}. Best is trial 3 with value: 0.9649122807017544.\n",
      "[I 2024-03-26 09:58:56,698] Trial 25 finished with value: 0.956140350877193 and parameters: {'booster': 'gbtree', 'max_depth': 5, 'learning_rate': 0.11112822514091536, 'n_estimators': 16, 'subsample': 0.7500700003697559, 'colsample_bytree': 0.6350510535735181}. Best is trial 3 with value: 0.9649122807017544.\n",
      "[I 2024-03-26 09:58:56,809] Trial 26 finished with value: 0.9649122807017544 and parameters: {'booster': 'dart', 'max_depth': 4, 'learning_rate': 0.15337633971538167, 'n_estimators': 52, 'subsample': 0.6761113443882293, 'colsample_bytree': 0.7174308566400659}. Best is trial 3 with value: 0.9649122807017544.\n",
      "[I 2024-03-26 09:58:56,895] Trial 27 finished with value: 0.9649122807017544 and parameters: {'booster': 'dart', 'max_depth': 10, 'learning_rate': 0.20482781230173086, 'n_estimators': 43, 'subsample': 0.7190626748426845, 'colsample_bytree': 0.6798191358466175}. Best is trial 3 with value: 0.9649122807017544.\n",
      "[I 2024-03-26 09:58:56,947] Trial 28 finished with value: 0.9122807017543859 and parameters: {'booster': 'gblinear', 'max_depth': 6, 'learning_rate': 0.013205379200723733, 'n_estimators': 31, 'subsample': 0.7312014293646439, 'colsample_bytree': 0.6269395254823359}. Best is trial 3 with value: 0.9649122807017544.\n",
      "[I 2024-03-26 09:58:57,049] Trial 29 finished with value: 0.9649122807017544 and parameters: {'booster': 'gbtree', 'max_depth': 9, 'learning_rate': 0.2424492445724745, 'n_estimators': 60, 'subsample': 0.6525017442741197, 'colsample_bytree': 0.7083225733791062}. Best is trial 3 with value: 0.9649122807017544.\n",
      "[I 2024-03-26 09:58:57,080] Trial 30 finished with value: 0.956140350877193 and parameters: {'booster': 'gblinear', 'max_depth': 8, 'learning_rate': 0.13364180866659542, 'n_estimators': 69, 'subsample': 0.6777957720040683, 'colsample_bytree': 0.7272691065920062}. Best is trial 3 with value: 0.9649122807017544.\n",
      "[I 2024-03-26 09:58:57,152] Trial 31 finished with value: 0.9649122807017544 and parameters: {'booster': 'dart', 'max_depth': 9, 'learning_rate': 0.2970101209801305, 'n_estimators': 35, 'subsample': 0.6967584828538946, 'colsample_bytree': 0.6848859565820977}. Best is trial 3 with value: 0.9649122807017544.\n",
      "[I 2024-03-26 09:58:57,241] Trial 32 finished with value: 0.9649122807017544 and parameters: {'booster': 'dart', 'max_depth': 9, 'learning_rate': 0.28208018102790466, 'n_estimators': 40, 'subsample': 0.6611324337904991, 'colsample_bytree': 0.7552651914799713}. Best is trial 3 with value: 0.9649122807017544.\n",
      "[I 2024-03-26 09:58:57,300] Trial 33 finished with value: 0.9649122807017544 and parameters: {'booster': 'dart', 'max_depth': 10, 'learning_rate': 0.2773312682864661, 'n_estimators': 16, 'subsample': 0.7019744029483679, 'colsample_bytree': 0.7008890617389104}. Best is trial 3 with value: 0.9649122807017544.\n",
      "[I 2024-03-26 09:58:57,364] Trial 34 finished with value: 0.9649122807017544 and parameters: {'booster': 'dart', 'max_depth': 8, 'learning_rate': 0.2587308586717957, 'n_estimators': 22, 'subsample': 0.6848072202743375, 'colsample_bytree': 0.6727792639092546}. Best is trial 3 with value: 0.9649122807017544.\n",
      "[I 2024-03-26 09:58:57,426] Trial 35 finished with value: 0.9649122807017544 and parameters: {'booster': 'dart', 'max_depth': 7, 'learning_rate': 0.29980286756898583, 'n_estimators': 30, 'subsample': 0.7094927723601558, 'colsample_bytree': 0.6464637702456527}. Best is trial 3 with value: 0.9649122807017544.\n",
      "[I 2024-03-26 09:58:57,458] Trial 36 finished with value: 0.6228070175438597 and parameters: {'booster': 'gblinear', 'max_depth': 10, 'learning_rate': 0.27542915037398785, 'n_estimators': 54, 'subsample': 0.6302332026350648, 'colsample_bytree': 0.6938639771018213}. Best is trial 3 with value: 0.9649122807017544.\n",
      "[I 2024-03-26 09:58:57,495] Trial 37 finished with value: 0.9649122807017544 and parameters: {'booster': 'gbtree', 'max_depth': 9, 'learning_rate': 0.2201019333114373, 'n_estimators': 15, 'subsample': 0.6657344961083145, 'colsample_bytree': 0.6724270568712392}. Best is trial 3 with value: 0.9649122807017544.\n",
      "[I 2024-03-26 09:58:57,575] Trial 38 finished with value: 0.9649122807017544 and parameters: {'booster': 'dart', 'max_depth': 8, 'learning_rate': 0.1882571155357619, 'n_estimators': 39, 'subsample': 0.7329008683029844, 'colsample_bytree': 0.7280007166521135}. Best is trial 3 with value: 0.9649122807017544.\n",
      "[I 2024-03-26 09:58:57,612] Trial 39 finished with value: 0.956140350877193 and parameters: {'booster': 'gbtree', 'max_depth': 8, 'learning_rate': 0.2592384415302293, 'n_estimators': 25, 'subsample': 0.6349035115357342, 'colsample_bytree': 0.6560135142186022}. Best is trial 3 with value: 0.9649122807017544.\n",
      "[I 2024-03-26 09:58:57,649] Trial 40 finished with value: 0.6228070175438597 and parameters: {'booster': 'gblinear', 'max_depth': 7, 'learning_rate': 0.282803475995838, 'n_estimators': 46, 'subsample': 0.6912323338844577, 'colsample_bytree': 0.7616786795944781}. Best is trial 3 with value: 0.9649122807017544.\n",
      "[I 2024-03-26 09:58:57,700] Trial 41 finished with value: 0.9649122807017544 and parameters: {'booster': 'gbtree', 'max_depth': 9, 'learning_rate': 0.2992321645516553, 'n_estimators': 37, 'subsample': 0.6710212296780704, 'colsample_bytree': 0.6122884897370457}. Best is trial 3 with value: 0.9649122807017544.\n",
      "[I 2024-03-26 09:58:57,754] Trial 42 finished with value: 0.9649122807017544 and parameters: {'booster': 'gbtree', 'max_depth': 9, 'learning_rate': 0.29045691469540963, 'n_estimators': 33, 'subsample': 0.6546856276753806, 'colsample_bytree': 0.6320871725593392}. Best is trial 3 with value: 0.9649122807017544.\n",
      "[I 2024-03-26 09:58:57,799] Trial 43 finished with value: 0.9649122807017544 and parameters: {'booster': 'gbtree', 'max_depth': 10, 'learning_rate': 0.27135844870425463, 'n_estimators': 57, 'subsample': 0.6750637769394748, 'colsample_bytree': 0.6002875100913629}. Best is trial 3 with value: 0.9649122807017544.\n",
      "[I 2024-03-26 09:58:57,859] Trial 44 finished with value: 0.9649122807017544 and parameters: {'booster': 'gbtree', 'max_depth': 9, 'learning_rate': 0.28481811514372113, 'n_estimators': 23, 'subsample': 0.7151647032135533, 'colsample_bytree': 0.6179515602282684}. Best is trial 3 with value: 0.9649122807017544.\n",
      "[I 2024-03-26 09:58:57,902] Trial 45 finished with value: 0.9649122807017544 and parameters: {'booster': 'gbtree', 'max_depth': 8, 'learning_rate': 0.24539083261886432, 'n_estimators': 49, 'subsample': 0.6967819320771675, 'colsample_bytree': 0.6444181979533274}. Best is trial 3 with value: 0.9649122807017544.\n",
      "[I 2024-03-26 09:58:57,987] Trial 46 finished with value: 0.9649122807017544 and parameters: {'booster': 'dart', 'max_depth': 10, 'learning_rate': 0.26904887214363477, 'n_estimators': 42, 'subsample': 0.6846740598200567, 'colsample_bytree': 0.624363550689775}. Best is trial 3 with value: 0.9649122807017544.\n",
      "[I 2024-03-26 09:58:58,038] Trial 47 finished with value: 0.9736842105263158 and parameters: {'booster': 'gbtree', 'max_depth': 6, 'learning_rate': 0.2301538600765593, 'n_estimators': 27, 'subsample': 0.6663463604050621, 'colsample_bytree': 0.6623645905999777}. Best is trial 47 with value: 0.9736842105263158.\n",
      "[I 2024-03-26 09:58:58,066] Trial 48 finished with value: 0.956140350877193 and parameters: {'booster': 'dart', 'max_depth': 3, 'learning_rate': 0.21413633248904623, 'n_estimators': 10, 'subsample': 0.659065174662728, 'colsample_bytree': 0.6633954818295322}. Best is trial 47 with value: 0.9736842105263158.\n",
      "[I 2024-03-26 09:58:58,119] Trial 49 finished with value: 0.9649122807017544 and parameters: {'booster': 'gbtree', 'max_depth': 6, 'learning_rate': 0.23901794962470818, 'n_estimators': 29, 'subsample': 0.6431370574045049, 'colsample_bytree': 0.6914458342438321}. Best is trial 47 with value: 0.9736842105263158.\n",
      "[I 2024-03-26 09:58:58,181] Trial 50 finished with value: 0.956140350877193 and parameters: {'booster': 'dart', 'max_depth': 4, 'learning_rate': 0.2319474436900758, 'n_estimators': 19, 'subsample': 0.6123296122112265, 'colsample_bytree': 0.6435874246123484}. Best is trial 47 with value: 0.9736842105263158.\n",
      "[I 2024-03-26 09:58:58,226] Trial 51 finished with value: 0.9649122807017544 and parameters: {'booster': 'gbtree', 'max_depth': 9, 'learning_rate': 0.26215721884851173, 'n_estimators': 26, 'subsample': 0.6679431169060798, 'colsample_bytree': 0.6577148588765322}. Best is trial 47 with value: 0.9736842105263158.\n",
      "[I 2024-03-26 09:58:58,264] Trial 52 finished with value: 0.9649122807017544 and parameters: {'booster': 'gbtree', 'max_depth': 5, 'learning_rate': 0.2524023164479259, 'n_estimators': 36, 'subsample': 0.7017927437828447, 'colsample_bytree': 0.6730671638711118}. Best is trial 47 with value: 0.9736842105263158.\n",
      "[I 2024-03-26 09:58:58,315] Trial 53 finished with value: 0.9649122807017544 and parameters: {'booster': 'gbtree', 'max_depth': 8, 'learning_rate': 0.2891319533717537, 'n_estimators': 65, 'subsample': 0.6862766721205515, 'colsample_bytree': 0.6178058573320989}. Best is trial 47 with value: 0.9736842105263158.\n",
      "[I 2024-03-26 09:58:58,355] Trial 54 finished with value: 0.9649122807017544 and parameters: {'booster': 'gbtree', 'max_depth': 6, 'learning_rate': 0.23231356244656434, 'n_estimators': 19, 'subsample': 0.7217918712404258, 'colsample_bytree': 0.6350362773192331}. Best is trial 47 with value: 0.9736842105263158.\n",
      "[I 2024-03-26 09:58:58,400] Trial 55 finished with value: 0.9649122807017544 and parameters: {'booster': 'gbtree', 'max_depth': 3, 'learning_rate': 0.27149746212467496, 'n_estimators': 45, 'subsample': 0.6451517200263934, 'colsample_bytree': 0.783464507373372}. Best is trial 47 with value: 0.9736842105263158.\n",
      "[I 2024-03-26 09:58:58,649] Trial 56 finished with value: 0.9736842105263158 and parameters: {'booster': 'dart', 'max_depth': 7, 'learning_rate': 0.25204663628163276, 'n_estimators': 81, 'subsample': 0.708312398082095, 'colsample_bytree': 0.8314102229283628}. Best is trial 47 with value: 0.9736842105263158.\n",
      "[I 2024-03-26 09:58:58,879] Trial 57 finished with value: 0.9649122807017544 and parameters: {'booster': 'dart', 'max_depth': 5, 'learning_rate': 0.21239589968739736, 'n_estimators': 80, 'subsample': 0.7096768670712444, 'colsample_bytree': 0.8295209820301231}. Best is trial 47 with value: 0.9736842105263158.\n",
      "[I 2024-03-26 09:58:59,161] Trial 58 finished with value: 0.9649122807017544 and parameters: {'booster': 'dart', 'max_depth': 7, 'learning_rate': 0.2509805630906082, 'n_estimators': 93, 'subsample': 0.7426818226746957, 'colsample_bytree': 0.8420339093231433}. Best is trial 47 with value: 0.9736842105263158.\n",
      "[I 2024-03-26 09:58:59,324] Trial 59 finished with value: 0.9649122807017544 and parameters: {'booster': 'dart', 'max_depth': 6, 'learning_rate': 0.20028133233269782, 'n_estimators': 76, 'subsample': 0.7203650815214971, 'colsample_bytree': 0.8097234819531787}. Best is trial 47 with value: 0.9736842105263158.\n",
      "[I 2024-03-26 09:58:59,533] Trial 60 finished with value: 0.9736842105263158 and parameters: {'booster': 'dart', 'max_depth': 7, 'learning_rate': 0.22148718478922372, 'n_estimators': 86, 'subsample': 0.6965769670257798, 'colsample_bytree': 0.8722976392817962}. Best is trial 47 with value: 0.9736842105263158.\n",
      "[I 2024-03-26 09:58:59,750] Trial 61 finished with value: 0.9736842105263158 and parameters: {'booster': 'dart', 'max_depth': 7, 'learning_rate': 0.22611299451346945, 'n_estimators': 87, 'subsample': 0.6965535457709968, 'colsample_bytree': 0.8687388068915547}. Best is trial 47 with value: 0.9736842105263158.\n",
      "[I 2024-03-26 09:58:59,933] Trial 62 finished with value: 0.9649122807017544 and parameters: {'booster': 'dart', 'max_depth': 7, 'learning_rate': 0.22371881220310916, 'n_estimators': 87, 'subsample': 0.6795377218065963, 'colsample_bytree': 0.8704788491206266}. Best is trial 47 with value: 0.9736842105263158.\n",
      "[I 2024-03-26 09:59:00,116] Trial 63 finished with value: 0.9649122807017544 and parameters: {'booster': 'dart', 'max_depth': 7, 'learning_rate': 0.23297304500295485, 'n_estimators': 87, 'subsample': 0.6995935453176827, 'colsample_bytree': 0.8853981030397683}. Best is trial 47 with value: 0.9736842105263158.\n",
      "[I 2024-03-26 09:59:00,316] Trial 64 finished with value: 0.9649122807017544 and parameters: {'booster': 'dart', 'max_depth': 7, 'learning_rate': 0.22097430005629004, 'n_estimators': 94, 'subsample': 0.7125525367968131, 'colsample_bytree': 0.8972543341382522}. Best is trial 47 with value: 0.9736842105263158.\n",
      "[I 2024-03-26 09:59:00,484] Trial 65 finished with value: 0.9649122807017544 and parameters: {'booster': 'dart', 'max_depth': 6, 'learning_rate': 0.2104951567107571, 'n_estimators': 87, 'subsample': 0.6930261634042137, 'colsample_bytree': 0.8599098982711258}. Best is trial 47 with value: 0.9736842105263158.\n",
      "[I 2024-03-26 09:59:00,699] Trial 66 finished with value: 0.9649122807017544 and parameters: {'booster': 'dart', 'max_depth': 5, 'learning_rate': 0.23870387997466883, 'n_estimators': 100, 'subsample': 0.7058590884603504, 'colsample_bytree': 0.8503448940190915}. Best is trial 47 with value: 0.9736842105263158.\n",
      "[I 2024-03-26 09:59:00,844] Trial 67 finished with value: 0.9649122807017544 and parameters: {'booster': 'dart', 'max_depth': 6, 'learning_rate': 0.24813944071153168, 'n_estimators': 78, 'subsample': 0.6819962016885694, 'colsample_bytree': 0.8271631529523423}. Best is trial 47 with value: 0.9736842105263158.\n",
      "[I 2024-03-26 09:59:00,877] Trial 68 finished with value: 0.9736842105263158 and parameters: {'booster': 'gblinear', 'max_depth': 7, 'learning_rate': 0.19402601221977972, 'n_estimators': 84, 'subsample': 0.6898693993475155, 'colsample_bytree': 0.8739768687406164}. Best is trial 47 with value: 0.9736842105263158.\n",
      "[I 2024-03-26 09:59:00,917] Trial 69 finished with value: 0.9736842105263158 and parameters: {'booster': 'gblinear', 'max_depth': 7, 'learning_rate': 0.20232660741094827, 'n_estimators': 83, 'subsample': 0.6720118648353132, 'colsample_bytree': 0.8752882206026803}. Best is trial 47 with value: 0.9736842105263158.\n",
      "[I 2024-03-26 09:59:00,950] Trial 70 finished with value: 0.9736842105263158 and parameters: {'booster': 'gblinear', 'max_depth': 7, 'learning_rate': 0.1976321213371619, 'n_estimators': 85, 'subsample': 0.6658291363428913, 'colsample_bytree': 0.87576723493538}. Best is trial 47 with value: 0.9736842105263158.\n",
      "[I 2024-03-26 09:59:00,981] Trial 71 finished with value: 0.9736842105263158 and parameters: {'booster': 'gblinear', 'max_depth': 7, 'learning_rate': 0.1946849391838976, 'n_estimators': 83, 'subsample': 0.6654286866800085, 'colsample_bytree': 0.8769590466088102}. Best is trial 47 with value: 0.9736842105263158.\n",
      "[I 2024-03-26 09:59:01,016] Trial 72 finished with value: 0.9736842105263158 and parameters: {'booster': 'gblinear', 'max_depth': 7, 'learning_rate': 0.19624698406382116, 'n_estimators': 83, 'subsample': 0.6638958659216958, 'colsample_bytree': 0.8794126804639012}. Best is trial 47 with value: 0.9736842105263158.\n",
      "[I 2024-03-26 09:59:01,059] Trial 73 finished with value: 0.9736842105263158 and parameters: {'booster': 'gblinear', 'max_depth': 7, 'learning_rate': 0.18478075926179027, 'n_estimators': 84, 'subsample': 0.6734804842694102, 'colsample_bytree': 0.8755032689439802}. Best is trial 47 with value: 0.9736842105263158.\n",
      "[I 2024-03-26 09:59:01,091] Trial 74 finished with value: 0.9736842105263158 and parameters: {'booster': 'gblinear', 'max_depth': 7, 'learning_rate': 0.20536994436822323, 'n_estimators': 92, 'subsample': 0.6522044384282124, 'colsample_bytree': 0.899949629641395}. Best is trial 47 with value: 0.9736842105263158.\n",
      "[I 2024-03-26 09:59:01,130] Trial 75 finished with value: 0.9736842105263158 and parameters: {'booster': 'gblinear', 'max_depth': 6, 'learning_rate': 0.1947317612538788, 'n_estimators': 97, 'subsample': 0.6620528167545537, 'colsample_bytree': 0.8705200014958815}. Best is trial 47 with value: 0.9736842105263158.\n",
      "[I 2024-03-26 09:59:01,185] Trial 76 finished with value: 0.9736842105263158 and parameters: {'booster': 'gblinear', 'max_depth': 7, 'learning_rate': 0.1914390091176288, 'n_estimators': 76, 'subsample': 0.6720045823735246, 'colsample_bytree': 0.8873365181864139}. Best is trial 47 with value: 0.9736842105263158.\n",
      "[I 2024-03-26 09:59:01,234] Trial 77 finished with value: 0.9736842105263158 and parameters: {'booster': 'gblinear', 'max_depth': 7, 'learning_rate': 0.17951796013162344, 'n_estimators': 83, 'subsample': 0.6886153916884185, 'colsample_bytree': 0.862166502283257}. Best is trial 47 with value: 0.9736842105263158.\n",
      "[I 2024-03-26 09:59:01,268] Trial 78 finished with value: 0.9736842105263158 and parameters: {'booster': 'gblinear', 'max_depth': 6, 'learning_rate': 0.2035233320100543, 'n_estimators': 90, 'subsample': 0.6764242687077278, 'colsample_bytree': 0.8797192564350647}. Best is trial 47 with value: 0.9736842105263158.\n",
      "[I 2024-03-26 09:59:01,301] Trial 79 finished with value: 0.9649122807017544 and parameters: {'booster': 'gblinear', 'max_depth': 7, 'learning_rate': 0.17071746962868753, 'n_estimators': 73, 'subsample': 0.6929112829973068, 'colsample_bytree': 0.8933209389521093}. Best is trial 47 with value: 0.9736842105263158.\n",
      "[I 2024-03-26 09:59:01,338] Trial 80 finished with value: 0.9649122807017544 and parameters: {'booster': 'gblinear', 'max_depth': 7, 'learning_rate': 0.2210932834122206, 'n_estimators': 96, 'subsample': 0.6562868162170687, 'colsample_bytree': 0.8898173775756397}. Best is trial 47 with value: 0.9736842105263158.\n",
      "[I 2024-03-26 09:59:01,369] Trial 81 finished with value: 0.9736842105263158 and parameters: {'booster': 'gblinear', 'max_depth': 7, 'learning_rate': 0.19715468835700947, 'n_estimators': 80, 'subsample': 0.665810602543889, 'colsample_bytree': 0.8827561022995071}. Best is trial 47 with value: 0.9736842105263158.\n",
      "[I 2024-03-26 09:59:01,400] Trial 82 finished with value: 0.9736842105263158 and parameters: {'booster': 'gblinear', 'max_depth': 8, 'learning_rate': 0.18413516415743905, 'n_estimators': 83, 'subsample': 0.6819515957366858, 'colsample_bytree': 0.8632053303165984}. Best is trial 47 with value: 0.9736842105263158.\n",
      "[I 2024-03-26 09:59:01,435] Trial 83 finished with value: 0.9736842105263158 and parameters: {'booster': 'gblinear', 'max_depth': 7, 'learning_rate': 0.2058155313241494, 'n_estimators': 90, 'subsample': 0.6693937905747213, 'colsample_bytree': 0.8776697905076585}. Best is trial 47 with value: 0.9736842105263158.\n",
      "[I 2024-03-26 09:59:01,466] Trial 84 finished with value: 0.9736842105263158 and parameters: {'booster': 'gblinear', 'max_depth': 6, 'learning_rate': 0.1915300821870574, 'n_estimators': 85, 'subsample': 0.6642661407093946, 'colsample_bytree': 0.8731261857549026}. Best is trial 47 with value: 0.9736842105263158.\n",
      "[I 2024-03-26 09:59:01,511] Trial 85 finished with value: 0.9649122807017544 and parameters: {'booster': 'gblinear', 'max_depth': 7, 'learning_rate': 0.21134441091555223, 'n_estimators': 82, 'subsample': 0.6497580242392497, 'colsample_bytree': 0.891783565210218}. Best is trial 47 with value: 0.9736842105263158.\n",
      "[I 2024-03-26 09:59:01,545] Trial 86 finished with value: 0.6228070175438597 and parameters: {'booster': 'gblinear', 'max_depth': 7, 'learning_rate': 0.22688612341225498, 'n_estimators': 78, 'subsample': 0.6373793716157249, 'colsample_bytree': 0.8551987897808824}. Best is trial 47 with value: 0.9736842105263158.\n",
      "[I 2024-03-26 09:59:01,586] Trial 87 finished with value: 0.9736842105263158 and parameters: {'booster': 'gblinear', 'max_depth': 8, 'learning_rate': 0.21725891152796256, 'n_estimators': 69, 'subsample': 0.6573028719946663, 'colsample_bytree': 0.8832034200272538}. Best is trial 47 with value: 0.9736842105263158.\n",
      "[I 2024-03-26 09:59:01,618] Trial 88 finished with value: 0.9385964912280702 and parameters: {'booster': 'gblinear', 'max_depth': 6, 'learning_rate': 0.1975602278086685, 'n_estimators': 88, 'subsample': 0.6866112825869755, 'colsample_bytree': 0.8676732576962103}. Best is trial 47 with value: 0.9736842105263158.\n",
      "[I 2024-03-26 09:59:01,651] Trial 89 finished with value: 0.9649122807017544 and parameters: {'booster': 'gblinear', 'max_depth': 7, 'learning_rate': 0.1780636171076642, 'n_estimators': 75, 'subsample': 0.7038880234382975, 'colsample_bytree': 0.8517844174656233}. Best is trial 47 with value: 0.9736842105263158.\n",
      "[I 2024-03-26 09:59:01,687] Trial 90 finished with value: 0.9649122807017544 and parameters: {'booster': 'gblinear', 'max_depth': 8, 'learning_rate': 0.16870398494028982, 'n_estimators': 85, 'subsample': 0.6944349299200807, 'colsample_bytree': 0.8438665998013186}. Best is trial 47 with value: 0.9736842105263158.\n",
      "[I 2024-03-26 09:59:01,725] Trial 91 finished with value: 0.9736842105263158 and parameters: {'booster': 'gblinear', 'max_depth': 7, 'learning_rate': 0.18688023885738386, 'n_estimators': 85, 'subsample': 0.6734720442331453, 'colsample_bytree': 0.875844396523001}. Best is trial 47 with value: 0.9736842105263158.\n",
      "[I 2024-03-26 09:59:01,759] Trial 92 finished with value: 0.9736842105263158 and parameters: {'booster': 'gblinear', 'max_depth': 7, 'learning_rate': 0.18387824350914095, 'n_estimators': 82, 'subsample': 0.6804263550864218, 'colsample_bytree': 0.8782445464069126}. Best is trial 47 with value: 0.9736842105263158.\n",
      "[I 2024-03-26 09:59:01,801] Trial 93 finished with value: 0.9736842105263158 and parameters: {'booster': 'gblinear', 'max_depth': 7, 'learning_rate': 0.20915966146951798, 'n_estimators': 91, 'subsample': 0.6611101979282581, 'colsample_bytree': 0.8672078873981378}. Best is trial 47 with value: 0.9736842105263158.\n",
      "[I 2024-03-26 09:59:01,832] Trial 94 finished with value: 0.9736842105263158 and parameters: {'booster': 'gblinear', 'max_depth': 7, 'learning_rate': 0.20095551043419937, 'n_estimators': 78, 'subsample': 0.6720739889336008, 'colsample_bytree': 0.874798154419002}. Best is trial 47 with value: 0.9736842105263158.\n",
      "[I 2024-03-26 09:59:01,873] Trial 95 finished with value: 0.9736842105263158 and parameters: {'booster': 'gblinear', 'max_depth': 6, 'learning_rate': 0.19268805002327088, 'n_estimators': 88, 'subsample': 0.6499214615440387, 'colsample_bytree': 0.8563576010085086}. Best is trial 47 with value: 0.9736842105263158.\n",
      "[I 2024-03-26 09:59:01,913] Trial 96 finished with value: 0.9736842105263158 and parameters: {'booster': 'gblinear', 'max_depth': 7, 'learning_rate': 0.21707706483106817, 'n_estimators': 80, 'subsample': 0.6983034375334216, 'colsample_bytree': 0.8635103439871863}. Best is trial 47 with value: 0.9736842105263158.\n",
      "[I 2024-03-26 09:59:02,034] Trial 97 finished with value: 0.6228070175438597 and parameters: {'booster': 'gblinear', 'max_depth': 8, 'learning_rate': 0.2266424647805584, 'n_estimators': 85, 'subsample': 0.6774038806753861, 'colsample_bytree': 0.8841437773300637}. Best is trial 47 with value: 0.9736842105263158.\n",
      "[I 2024-03-26 09:59:02,075] Trial 98 finished with value: 0.9736842105263158 and parameters: {'booster': 'gblinear', 'max_depth': 7, 'learning_rate': 0.17625856677142546, 'n_estimators': 89, 'subsample': 0.6681769150380275, 'colsample_bytree': 0.8942127896476831}. Best is trial 47 with value: 0.9736842105263158.\n",
      "[I 2024-03-26 09:59:02,109] Trial 99 finished with value: 0.9736842105263158 and parameters: {'booster': 'gblinear', 'max_depth': 7, 'learning_rate': 0.16071026839240132, 'n_estimators': 95, 'subsample': 0.688219244037716, 'colsample_bytree': 0.8687212782487449}. Best is trial 47 with value: 0.9736842105263158.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TBest Hyperparameters from Optuna:\n",
      "{'booster': 'gbtree', 'max_depth': 6, 'learning_rate': 0.2301538600765593, 'n_estimators': 27, 'subsample': 0.6663463604050621, 'colsample_bytree': 0.6623645905999777}\n",
      "Best XGBoost Classifier Performance:\n",
      "Accuracy: 0.97\n",
      "Precision: 0.96\n",
      "Recall: 1.00\n",
      "F1-Score: 0.98\n",
      "ROC-AUC: 0.97\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "best_params = study.best_params\n",
    "best_model = xgb.XGBClassifier(**best_params)\n",
    "\n",
    "best_model.fit(X_train, y_train)\n",
    "y_pred = best_model.predict(X_test)\n",
    "best_accuracy = accuracy_score(y_test, y_pred)\n",
    "best_precision = precision_score(y_test, y_pred)\n",
    "best_recall = recall_score(y_test, y_pred)\n",
    "best_f1 = f1_score(y_test, y_pred)\n",
    "best_roc_auc = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "print(\"TBest Hyperparameters from Optuna:\")\n",
    "print(best_params)\n",
    "\n",
    "print(\"Best XGBoost Classifier Performance:\")\n",
    "print(f\"Accuracy: {best_accuracy:.2f}\")\n",
    "print(f\"Precision: {best_precision:.2f}\")\n",
    "print(f\"Recall: {best_recall:.2f}\")\n",
    "print(f\"F1-Score: {best_f1:.2f}\")\n",
    "print(f\"ROC-AUC: {best_roc_auc:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "universe",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
