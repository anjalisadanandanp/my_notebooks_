{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBOOST for classification and Hyperparameter using Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "\n",
    "import optuna\n",
    "import xgboost as xgb\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading data\n",
    "breast_cancer = load_breast_cancer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _breast_cancer_dataset:\n",
      "\n",
      "Breast cancer wisconsin (diagnostic) dataset\n",
      "--------------------------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 569\n",
      "\n",
      "    :Number of Attributes: 30 numeric, predictive attributes and the class\n",
      "\n",
      "    :Attribute Information:\n",
      "        - radius (mean of distances from center to points on the perimeter)\n",
      "        - texture (standard deviation of gray-scale values)\n",
      "        - perimeter\n",
      "        - area\n",
      "        - smoothness (local variation in radius lengths)\n",
      "        - compactness (perimeter^2 / area - 1.0)\n",
      "        - concavity (severity of concave portions of the contour)\n",
      "        - concave points (number of concave portions of the contour)\n",
      "        - symmetry\n",
      "        - fractal dimension (\"coastline approximation\" - 1)\n",
      "\n",
      "        The mean, standard error, and \"worst\" or largest (mean of the three\n",
      "        worst/largest values) of these features were computed for each image,\n",
      "        resulting in 30 features.  For instance, field 0 is Mean Radius, field\n",
      "        10 is Radius SE, field 20 is Worst Radius.\n",
      "\n",
      "        - class:\n",
      "                - WDBC-Malignant\n",
      "                - WDBC-Benign\n",
      "\n",
      "    :Summary Statistics:\n",
      "\n",
      "    ===================================== ====== ======\n",
      "                                           Min    Max\n",
      "    ===================================== ====== ======\n",
      "    radius (mean):                        6.981  28.11\n",
      "    texture (mean):                       9.71   39.28\n",
      "    perimeter (mean):                     43.79  188.5\n",
      "    area (mean):                          143.5  2501.0\n",
      "    smoothness (mean):                    0.053  0.163\n",
      "    compactness (mean):                   0.019  0.345\n",
      "    concavity (mean):                     0.0    0.427\n",
      "    concave points (mean):                0.0    0.201\n",
      "    symmetry (mean):                      0.106  0.304\n",
      "    fractal dimension (mean):             0.05   0.097\n",
      "    radius (standard error):              0.112  2.873\n",
      "    texture (standard error):             0.36   4.885\n",
      "    perimeter (standard error):           0.757  21.98\n",
      "    area (standard error):                6.802  542.2\n",
      "    smoothness (standard error):          0.002  0.031\n",
      "    compactness (standard error):         0.002  0.135\n",
      "    concavity (standard error):           0.0    0.396\n",
      "    concave points (standard error):      0.0    0.053\n",
      "    symmetry (standard error):            0.008  0.079\n",
      "    fractal dimension (standard error):   0.001  0.03\n",
      "    radius (worst):                       7.93   36.04\n",
      "    texture (worst):                      12.02  49.54\n",
      "    perimeter (worst):                    50.41  251.2\n",
      "    area (worst):                         185.2  4254.0\n",
      "    smoothness (worst):                   0.071  0.223\n",
      "    compactness (worst):                  0.027  1.058\n",
      "    concavity (worst):                    0.0    1.252\n",
      "    concave points (worst):               0.0    0.291\n",
      "    symmetry (worst):                     0.156  0.664\n",
      "    fractal dimension (worst):            0.055  0.208\n",
      "    ===================================== ====== ======\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "    :Class Distribution: 212 - Malignant, 357 - Benign\n",
      "\n",
      "    :Creator:  Dr. William H. Wolberg, W. Nick Street, Olvi L. Mangasarian\n",
      "\n",
      "    :Donor: Nick Street\n",
      "\n",
      "    :Date: November, 1995\n",
      "\n",
      "This is a copy of UCI ML Breast Cancer Wisconsin (Diagnostic) datasets.\n",
      "https://goo.gl/U2Uwz2\n",
      "\n",
      "Features are computed from a digitized image of a fine needle\n",
      "aspirate (FNA) of a breast mass.  They describe\n",
      "characteristics of the cell nuclei present in the image.\n",
      "\n",
      "Separating plane described above was obtained using\n",
      "Multisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree\n",
      "Construction Via Linear Programming.\" Proceedings of the 4th\n",
      "Midwest Artificial Intelligence and Cognitive Science Society,\n",
      "pp. 97-101, 1992], a classification method which uses linear\n",
      "programming to construct a decision tree.  Relevant features\n",
      "were selected using an exhaustive search in the space of 1-4\n",
      "features and 1-3 separating planes.\n",
      "\n",
      "The actual linear program used to obtain the separating plane\n",
      "in the 3-dimensional space is that described in:\n",
      "[K. P. Bennett and O. L. Mangasarian: \"Robust Linear\n",
      "Programming Discrimination of Two Linearly Inseparable Sets\",\n",
      "Optimization Methods and Software 1, 1992, 23-34].\n",
      "\n",
      "This database is also available through the UW CS ftp server:\n",
      "\n",
      "ftp ftp.cs.wisc.edu\n",
      "cd math-prog/cpo-dataset/machine-learn/WDBC/\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "   - W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction \n",
      "     for breast tumor diagnosis. IS&T/SPIE 1993 International Symposium on \n",
      "     Electronic Imaging: Science and Technology, volume 1905, pages 861-870,\n",
      "     San Jose, CA, 1993.\n",
      "   - O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and \n",
      "     prognosis via linear programming. Operations Research, 43(4), pages 570-577, \n",
      "     July-August 1995.\n",
      "   - W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Machine learning techniques\n",
      "     to diagnose breast cancer from fine-needle aspirates. Cancer Letters 77 (1994) \n",
      "     163-171.\n"
     ]
    }
   ],
   "source": [
    "#Describe the dataset\n",
    "print(breast_cancer.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mean radius' 'mean texture' 'mean perimeter' 'mean area'\n",
      " 'mean smoothness' 'mean compactness' 'mean concavity'\n",
      " 'mean concave points' 'mean symmetry' 'mean fractal dimension'\n",
      " 'radius error' 'texture error' 'perimeter error' 'area error'\n",
      " 'smoothness error' 'compactness error' 'concavity error'\n",
      " 'concave points error' 'symmetry error' 'fractal dimension error'\n",
      " 'worst radius' 'worst texture' 'worst perimeter' 'worst area'\n",
      " 'worst smoothness' 'worst compactness' 'worst concavity'\n",
      " 'worst concave points' 'worst symmetry' 'worst fractal dimension']\n"
     ]
    }
   ],
   "source": [
    "#print the features of the dataset\n",
    "print(breast_cancer.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['malignant' 'benign']\n"
     ]
    }
   ],
   "source": [
    "#print the target of the dataset\n",
    "print(breast_cancer.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = breast_cancer.data\n",
    "y = breast_cancer.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape:  (455, 30)\n",
      "X_test shape:  (114, 30)\n",
      "y_train shape:  (455,)\n",
      "y_test shape:  (114,)\n"
     ]
    }
   ],
   "source": [
    "#printing the shapes of the train and test sets\n",
    "print(\"X_train shape: \", X_train.shape)\n",
    "print(\"X_test shape: \", X_test.shape)\n",
    "print(\"y_train shape: \", y_train.shape)\n",
    "print(\"y_test shape: \", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=None, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=None, ...)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fit a XGBoost Classifier with default parameters\n",
    "clf_xgb = xgb.XGBClassifier()\n",
    "clf_xgb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 2: Default XGBoost Classifier Performance:\n",
      "Accuracy: 0.96\n",
      "Precision: 0.96\n",
      "Recall: 0.97\n",
      "F1-Score: 0.97\n",
      "ROC-AUC: 0.95\n"
     ]
    }
   ],
   "source": [
    "#predict the test set\n",
    "y_pred = clf_xgb.predict(X_test)\n",
    "\n",
    "#calculate the performance metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "print(\"Task 2: Default XGBoost Classifier Performance:\")\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1-Score: {f1:.2f}\")\n",
    "print(f\"ROC-AUC: {roc_auc:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter using Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining the objective function\n",
    "\n",
    "def objective(trial):\n",
    "\n",
    "    params = {\n",
    "        \"verbosity\": 0,\n",
    "        \"objective\": \"binary:logistic\",\n",
    "        \"booster\": trial.suggest_categorical(\"booster\", [\"gbtree\", \"gblinear\", \"dart\"]),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 10),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.3),\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 10, 100, step=1),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.6, 0.9),\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.6, 0.9),\n",
    "    }\n",
    "\n",
    "    model = xgb.XGBClassifier(**params)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = sklearn.metrics.accuracy_score(y_test, y_pred)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-10-04 18:59:34,411] A new study created in memory with name: no-name-ae87f0dd-3cca-41fe-9260-2d6d02167942\n",
      "[I 2023-10-04 18:59:50,967] Trial 0 finished with value: 0.9649122807017544 and parameters: {'booster': 'gbtree', 'max_depth': 7, 'learning_rate': 0.1919154179947743, 'n_estimators': 33, 'subsample': 0.6658746970180826, 'colsample_bytree': 0.8661643381673766}. Best is trial 0 with value: 0.9649122807017544.\n",
      "[I 2023-10-04 18:59:56,167] Trial 1 finished with value: 0.9736842105263158 and parameters: {'booster': 'gbtree', 'max_depth': 8, 'learning_rate': 0.23314258023458886, 'n_estimators': 46, 'subsample': 0.7914360382192613, 'colsample_bytree': 0.8693677274293565}. Best is trial 1 with value: 0.9736842105263158.\n",
      "[I 2023-10-04 18:59:57,296] Trial 2 finished with value: 0.956140350877193 and parameters: {'booster': 'gblinear', 'max_depth': 5, 'learning_rate': 0.14472915075332654, 'n_estimators': 69, 'subsample': 0.6797303742139931, 'colsample_bytree': 0.8781268294023192}. Best is trial 1 with value: 0.9736842105263158.\n",
      "[I 2023-10-04 19:01:16,181] Trial 3 finished with value: 0.9649122807017544 and parameters: {'booster': 'dart', 'max_depth': 9, 'learning_rate': 0.14573112479429254, 'n_estimators': 91, 'subsample': 0.7794726576956673, 'colsample_bytree': 0.6573036671709449}. Best is trial 1 with value: 0.9736842105263158.\n",
      "[I 2023-10-04 19:01:36,328] Trial 4 finished with value: 0.9649122807017544 and parameters: {'booster': 'gbtree', 'max_depth': 7, 'learning_rate': 0.09078532611714828, 'n_estimators': 69, 'subsample': 0.7831951807796216, 'colsample_bytree': 0.6579463952088482}. Best is trial 1 with value: 0.9736842105263158.\n",
      "[I 2023-10-04 19:01:44,307] Trial 5 finished with value: 0.9649122807017544 and parameters: {'booster': 'dart', 'max_depth': 5, 'learning_rate': 0.1427108026698677, 'n_estimators': 39, 'subsample': 0.6062834177874009, 'colsample_bytree': 0.7858886188518306}. Best is trial 1 with value: 0.9736842105263158.\n",
      "[I 2023-10-04 19:02:08,077] Trial 6 finished with value: 0.956140350877193 and parameters: {'booster': 'dart', 'max_depth': 7, 'learning_rate': 0.05902263990518068, 'n_estimators': 41, 'subsample': 0.7320043728859791, 'colsample_bytree': 0.6181820435147802}. Best is trial 1 with value: 0.9736842105263158.\n",
      "[I 2023-10-04 19:02:15,488] Trial 7 finished with value: 0.956140350877193 and parameters: {'booster': 'gblinear', 'max_depth': 10, 'learning_rate': 0.10992731616895463, 'n_estimators': 55, 'subsample': 0.7872942810472828, 'colsample_bytree': 0.6129897400173671}. Best is trial 1 with value: 0.9736842105263158.\n",
      "[I 2023-10-04 19:02:24,386] Trial 8 finished with value: 0.956140350877193 and parameters: {'booster': 'gblinear', 'max_depth': 5, 'learning_rate': 0.1027060910935165, 'n_estimators': 85, 'subsample': 0.821739151941759, 'colsample_bytree': 0.7747388974159932}. Best is trial 1 with value: 0.9736842105263158.\n",
      "[I 2023-10-04 19:02:28,777] Trial 9 finished with value: 0.9385964912280702 and parameters: {'booster': 'gblinear', 'max_depth': 3, 'learning_rate': 0.018457802820914276, 'n_estimators': 62, 'subsample': 0.8913747073870397, 'colsample_bytree': 0.6759236655780367}. Best is trial 1 with value: 0.9736842105263158.\n",
      "[I 2023-10-04 19:02:29,164] Trial 10 finished with value: 0.956140350877193 and parameters: {'booster': 'gbtree', 'max_depth': 9, 'learning_rate': 0.2879223512239668, 'n_estimators': 12, 'subsample': 0.8676626141335788, 'colsample_bytree': 0.8305850127214853}. Best is trial 1 with value: 0.9736842105263158.\n",
      "[I 2023-10-04 19:02:43,367] Trial 11 finished with value: 0.9649122807017544 and parameters: {'booster': 'gbtree', 'max_depth': 8, 'learning_rate': 0.22222589680296123, 'n_estimators': 23, 'subsample': 0.7079175177933253, 'colsample_bytree': 0.8842157286937459}. Best is trial 1 with value: 0.9736842105263158.\n",
      "[I 2023-10-04 19:02:49,573] Trial 12 finished with value: 0.9649122807017544 and parameters: {'booster': 'gbtree', 'max_depth': 6, 'learning_rate': 0.21018063905841552, 'n_estimators': 37, 'subsample': 0.6624054760577051, 'colsample_bytree': 0.8402014709389454}. Best is trial 1 with value: 0.9736842105263158.\n",
      "[I 2023-10-04 19:02:51,705] Trial 13 finished with value: 0.9649122807017544 and parameters: {'booster': 'gbtree', 'max_depth': 8, 'learning_rate': 0.20584123799792486, 'n_estimators': 27, 'subsample': 0.7197392042351345, 'colsample_bytree': 0.890165212955119}. Best is trial 1 with value: 0.9736842105263158.\n",
      "[I 2023-10-04 19:02:58,458] Trial 14 finished with value: 0.9649122807017544 and parameters: {'booster': 'gbtree', 'max_depth': 8, 'learning_rate': 0.26007819503669327, 'n_estimators': 50, 'subsample': 0.6223814401061878, 'colsample_bytree': 0.8416074462646562}. Best is trial 1 with value: 0.9736842105263158.\n",
      "[I 2023-10-04 19:02:58,966] Trial 15 finished with value: 0.956140350877193 and parameters: {'booster': 'gbtree', 'max_depth': 6, 'learning_rate': 0.18215767693046195, 'n_estimators': 10, 'subsample': 0.7589034540366475, 'colsample_bytree': 0.8016840623065098}. Best is trial 1 with value: 0.9736842105263158.\n",
      "[I 2023-10-04 19:03:00,648] Trial 16 finished with value: 0.956140350877193 and parameters: {'booster': 'gbtree', 'max_depth': 10, 'learning_rate': 0.24622890728223418, 'n_estimators': 26, 'subsample': 0.6670114941676065, 'colsample_bytree': 0.7372514122570409}. Best is trial 1 with value: 0.9736842105263158.\n",
      "[I 2023-10-04 19:03:08,717] Trial 17 finished with value: 0.9649122807017544 and parameters: {'booster': 'gbtree', 'max_depth': 3, 'learning_rate': 0.18527092743916587, 'n_estimators': 47, 'subsample': 0.8321556801119294, 'colsample_bytree': 0.8942415882635462}. Best is trial 1 with value: 0.9736842105263158.\n",
      "[I 2023-10-04 19:03:19,923] Trial 18 finished with value: 0.9649122807017544 and parameters: {'booster': 'gbtree', 'max_depth': 9, 'learning_rate': 0.28299745167440105, 'n_estimators': 78, 'subsample': 0.7450865078720056, 'colsample_bytree': 0.8535744920247594}. Best is trial 1 with value: 0.9736842105263158.\n",
      "[I 2023-10-04 19:03:24,082] Trial 19 finished with value: 0.9649122807017544 and parameters: {'booster': 'dart', 'max_depth': 7, 'learning_rate': 0.24271349143991566, 'n_estimators': 58, 'subsample': 0.6958859348130036, 'colsample_bytree': 0.8078040053055469}. Best is trial 1 with value: 0.9736842105263158.\n",
      "[I 2023-10-04 19:03:24,152] Trial 20 finished with value: 0.9649122807017544 and parameters: {'booster': 'gbtree', 'max_depth': 4, 'learning_rate': 0.17688155314447898, 'n_estimators': 33, 'subsample': 0.6373485264825497, 'colsample_bytree': 0.8624892463182975}. Best is trial 1 with value: 0.9736842105263158.\n",
      "[I 2023-10-04 19:03:44,353] Trial 21 finished with value: 0.9649122807017544 and parameters: {'booster': 'dart', 'max_depth': 9, 'learning_rate': 0.16258700988019018, 'n_estimators': 85, 'subsample': 0.7656555058397535, 'colsample_bytree': 0.7318187729142627}. Best is trial 1 with value: 0.9736842105263158.\n",
      "[I 2023-10-04 19:05:20,907] Trial 22 finished with value: 0.9649122807017544 and parameters: {'booster': 'dart', 'max_depth': 8, 'learning_rate': 0.2235379527307543, 'n_estimators': 95, 'subsample': 0.731642147184343, 'colsample_bytree': 0.708510120597424}. Best is trial 1 with value: 0.9736842105263158.\n",
      "[I 2023-10-04 19:05:28,806] Trial 23 finished with value: 0.9649122807017544 and parameters: {'booster': 'dart', 'max_depth': 9, 'learning_rate': 0.13657373405603812, 'n_estimators': 46, 'subsample': 0.80242575785563, 'colsample_bytree': 0.7703316620735322}. Best is trial 1 with value: 0.9736842105263158.\n",
      "[I 2023-10-04 19:05:46,142] Trial 24 finished with value: 0.956140350877193 and parameters: {'booster': 'dart', 'max_depth': 10, 'learning_rate': 0.20001076625934985, 'n_estimators': 19, 'subsample': 0.75788056683231, 'colsample_bytree': 0.8231062350057348}. Best is trial 1 with value: 0.9736842105263158.\n",
      "[I 2023-10-04 19:07:02,428] Trial 25 finished with value: 0.9649122807017544 and parameters: {'booster': 'dart', 'max_depth': 7, 'learning_rate': 0.1601884208928294, 'n_estimators': 94, 'subsample': 0.7040578540034977, 'colsample_bytree': 0.8623024015944761}. Best is trial 1 with value: 0.9736842105263158.\n",
      "[I 2023-10-04 19:07:17,389] Trial 26 finished with value: 0.9649122807017544 and parameters: {'booster': 'gbtree', 'max_depth': 8, 'learning_rate': 0.1939935644609919, 'n_estimators': 31, 'subsample': 0.7814826689722322, 'colsample_bytree': 0.8989684455753368}. Best is trial 1 with value: 0.9736842105263158.\n",
      "[I 2023-10-04 19:07:18,476] Trial 27 finished with value: 0.4824561403508772 and parameters: {'booster': 'gblinear', 'max_depth': 6, 'learning_rate': 0.2304228825638287, 'n_estimators': 63, 'subsample': 0.7405651640286879, 'colsample_bytree': 0.8173944288496905}. Best is trial 1 with value: 0.9736842105263158.\n",
      "[I 2023-10-04 19:07:22,071] Trial 28 finished with value: 0.9649122807017544 and parameters: {'booster': 'gbtree', 'max_depth': 9, 'learning_rate': 0.17045611829721422, 'n_estimators': 51, 'subsample': 0.8126502140182742, 'colsample_bytree': 0.7559458199879652}. Best is trial 1 with value: 0.9736842105263158.\n",
      "[I 2023-10-04 19:08:01,311] Trial 29 finished with value: 0.9649122807017544 and parameters: {'booster': 'dart', 'max_depth': 7, 'learning_rate': 0.14227120578510918, 'n_estimators': 71, 'subsample': 0.6873866554462906, 'colsample_bytree': 0.8664723398410511}. Best is trial 1 with value: 0.9736842105263158.\n",
      "[I 2023-10-04 19:08:07,802] Trial 30 finished with value: 0.9649122807017544 and parameters: {'booster': 'gblinear', 'max_depth': 8, 'learning_rate': 0.261866806239838, 'n_estimators': 43, 'subsample': 0.8376178058339754, 'colsample_bytree': 0.8768977248028198}. Best is trial 1 with value: 0.9736842105263158.\n",
      "[I 2023-10-04 19:08:28,083] Trial 31 finished with value: 0.9649122807017544 and parameters: {'booster': 'gbtree', 'max_depth': 7, 'learning_rate': 0.11598931186018477, 'n_estimators': 100, 'subsample': 0.7804381386105411, 'colsample_bytree': 0.653772938451115}. Best is trial 1 with value: 0.9736842105263158.\n",
      "[I 2023-10-04 19:08:43,984] Trial 32 finished with value: 0.9649122807017544 and parameters: {'booster': 'gbtree', 'max_depth': 6, 'learning_rate': 0.12846696099671534, 'n_estimators': 75, 'subsample': 0.7912956337454511, 'colsample_bytree': 0.6904726136902856}. Best is trial 1 with value: 0.9736842105263158.\n",
      "[I 2023-10-04 19:08:50,944] Trial 33 finished with value: 0.9649122807017544 and parameters: {'booster': 'gbtree', 'max_depth': 7, 'learning_rate': 0.08278669363959218, 'n_estimators': 85, 'subsample': 0.7658858895402884, 'colsample_bytree': 0.6616712386910797}. Best is trial 1 with value: 0.9736842105263158.\n",
      "[I 2023-10-04 19:09:11,082] Trial 34 finished with value: 0.9649122807017544 and parameters: {'booster': 'gbtree', 'max_depth': 5, 'learning_rate': 0.14633701566334342, 'n_estimators': 63, 'subsample': 0.7191108677453452, 'colsample_bytree': 0.6340574641573721}. Best is trial 1 with value: 0.9736842105263158.\n",
      "[I 2023-10-04 19:09:35,992] Trial 35 finished with value: 0.9649122807017544 and parameters: {'booster': 'dart', 'max_depth': 8, 'learning_rate': 0.15712174614598398, 'n_estimators': 55, 'subsample': 0.8030551756454559, 'colsample_bytree': 0.6078535393502998}. Best is trial 1 with value: 0.9736842105263158.\n",
      "[I 2023-10-04 19:09:38,143] Trial 36 finished with value: 0.9473684210526315 and parameters: {'booster': 'gblinear', 'max_depth': 5, 'learning_rate': 0.091934083397871, 'n_estimators': 38, 'subsample': 0.7804554397161492, 'colsample_bytree': 0.6374499218106306}. Best is trial 1 with value: 0.9736842105263158.\n",
      "[I 2023-10-04 19:09:52,604] Trial 37 finished with value: 0.9649122807017544 and parameters: {'booster': 'gbtree', 'max_depth': 10, 'learning_rate': 0.12288802290627306, 'n_estimators': 68, 'subsample': 0.820381283626796, 'colsample_bytree': 0.6966512401294476}. Best is trial 1 with value: 0.9736842105263158.\n",
      "[I 2023-10-04 19:09:53,631] Trial 38 finished with value: 0.956140350877193 and parameters: {'booster': 'gbtree', 'max_depth': 9, 'learning_rate': 0.061052831060969134, 'n_estimators': 17, 'subsample': 0.742550109058446, 'colsample_bytree': 0.625374758243838}. Best is trial 1 with value: 0.9736842105263158.\n",
      "[I 2023-10-04 19:10:36,483] Trial 39 finished with value: 0.9649122807017544 and parameters: {'booster': 'dart', 'max_depth': 6, 'learning_rate': 0.10437187235828667, 'n_estimators': 83, 'subsample': 0.77146149281912, 'colsample_bytree': 0.6051696716391082}. Best is trial 1 with value: 0.9736842105263158.\n",
      "[I 2023-10-04 19:10:39,860] Trial 40 finished with value: 0.9824561403508771 and parameters: {'booster': 'gblinear', 'max_depth': 7, 'learning_rate': 0.2112313669279117, 'n_estimators': 91, 'subsample': 0.8484044756625635, 'colsample_bytree': 0.672932967850814}. Best is trial 40 with value: 0.9824561403508771.\n",
      "[I 2023-10-04 19:10:41,109] Trial 41 finished with value: 0.9736842105263158 and parameters: {'booster': 'gblinear', 'max_depth': 7, 'learning_rate': 0.19858945665709204, 'n_estimators': 94, 'subsample': 0.8520832530751306, 'colsample_bytree': 0.6660531744962866}. Best is trial 40 with value: 0.9824561403508771.\n",
      "[I 2023-10-04 19:10:52,832] Trial 42 finished with value: 0.9649122807017544 and parameters: {'booster': 'gblinear', 'max_depth': 7, 'learning_rate': 0.21387567325353343, 'n_estimators': 90, 'subsample': 0.8501431928951954, 'colsample_bytree': 0.6657230538938298}. Best is trial 40 with value: 0.9824561403508771.\n",
      "[I 2023-10-04 19:10:57,709] Trial 43 finished with value: 0.9736842105263158 and parameters: {'booster': 'gblinear', 'max_depth': 8, 'learning_rate': 0.19143135172543235, 'n_estimators': 90, 'subsample': 0.8769553136008028, 'colsample_bytree': 0.6474157949238032}. Best is trial 40 with value: 0.9824561403508771.\n",
      "[I 2023-10-04 19:11:02,311] Trial 44 finished with value: 0.9736842105263158 and parameters: {'booster': 'gblinear', 'max_depth': 8, 'learning_rate': 0.19373071624820212, 'n_estimators': 90, 'subsample': 0.8796069031989582, 'colsample_bytree': 0.6451984933076267}. Best is trial 40 with value: 0.9824561403508771.\n",
      "[I 2023-10-04 19:11:04,710] Trial 45 finished with value: 0.9736842105263158 and parameters: {'booster': 'gblinear', 'max_depth': 8, 'learning_rate': 0.19441233145870274, 'n_estimators': 99, 'subsample': 0.8831288059394509, 'colsample_bytree': 0.6411521673693197}. Best is trial 40 with value: 0.9824561403508771.\n",
      "[I 2023-10-04 19:11:04,876] Trial 46 finished with value: 0.9824561403508771 and parameters: {'booster': 'gblinear', 'max_depth': 7, 'learning_rate': 0.21054623990465593, 'n_estimators': 80, 'subsample': 0.8666964487789048, 'colsample_bytree': 0.6754420548261729}. Best is trial 40 with value: 0.9824561403508771.\n",
      "[I 2023-10-04 19:11:15,593] Trial 47 finished with value: 0.9649122807017544 and parameters: {'booster': 'gblinear', 'max_depth': 7, 'learning_rate': 0.21474718252215563, 'n_estimators': 79, 'subsample': 0.8615244964472569, 'colsample_bytree': 0.6747682349010112}. Best is trial 40 with value: 0.9824561403508771.\n",
      "[I 2023-10-04 19:11:25,767] Trial 48 finished with value: 0.9649122807017544 and parameters: {'booster': 'gblinear', 'max_depth': 6, 'learning_rate': 0.20282950373740846, 'n_estimators': 92, 'subsample': 0.8527803931912754, 'colsample_bytree': 0.6249606706113482}. Best is trial 40 with value: 0.9824561403508771.\n",
      "[I 2023-10-04 19:11:39,382] Trial 49 finished with value: 0.9649122807017544 and parameters: {'booster': 'gblinear', 'max_depth': 7, 'learning_rate': 0.17777019870846664, 'n_estimators': 96, 'subsample': 0.8931436321286746, 'colsample_bytree': 0.6507735673205062}. Best is trial 40 with value: 0.9824561403508771.\n",
      "[I 2023-10-04 19:11:48,797] Trial 50 finished with value: 0.9649122807017544 and parameters: {'booster': 'gblinear', 'max_depth': 8, 'learning_rate': 0.23468918274061326, 'n_estimators': 88, 'subsample': 0.8765772072918834, 'colsample_bytree': 0.6739758999978078}. Best is trial 40 with value: 0.9824561403508771.\n",
      "[I 2023-10-04 19:11:57,327] Trial 51 finished with value: 0.9649122807017544 and parameters: {'booster': 'gblinear', 'max_depth': 8, 'learning_rate': 0.21065383600105167, 'n_estimators': 88, 'subsample': 0.8709892357933037, 'colsample_bytree': 0.6488249895316309}. Best is trial 40 with value: 0.9824561403508771.\n",
      "[I 2023-10-04 19:12:07,979] Trial 52 finished with value: 0.9649122807017544 and parameters: {'booster': 'gblinear', 'max_depth': 8, 'learning_rate': 0.19200085592028562, 'n_estimators': 91, 'subsample': 0.899977192367589, 'colsample_bytree': 0.6162683204492573}. Best is trial 40 with value: 0.9824561403508771.\n",
      "[I 2023-10-04 19:12:16,579] Trial 53 finished with value: 0.9649122807017544 and parameters: {'booster': 'gblinear', 'max_depth': 7, 'learning_rate': 0.22423013169387, 'n_estimators': 81, 'subsample': 0.864257893956621, 'colsample_bytree': 0.6877084752022045}. Best is trial 40 with value: 0.9824561403508771.\n",
      "[I 2023-10-04 19:12:21,889] Trial 54 finished with value: 0.9736842105263158 and parameters: {'booster': 'gblinear', 'max_depth': 9, 'learning_rate': 0.1819081224315468, 'n_estimators': 96, 'subsample': 0.8793060664429794, 'colsample_bytree': 0.6616853592817554}. Best is trial 40 with value: 0.9824561403508771.\n",
      "[I 2023-10-04 19:12:22,656] Trial 55 finished with value: 0.9736842105263158 and parameters: {'booster': 'gblinear', 'max_depth': 8, 'learning_rate': 0.19855371951307108, 'n_estimators': 76, 'subsample': 0.8406377701360577, 'colsample_bytree': 0.7089175464472073}. Best is trial 40 with value: 0.9824561403508771.\n",
      "[I 2023-10-04 19:12:22,723] Trial 56 finished with value: 0.6228070175438597 and parameters: {'booster': 'gblinear', 'max_depth': 7, 'learning_rate': 0.21614645642722502, 'n_estimators': 85, 'subsample': 0.8577364661158531, 'colsample_bytree': 0.6502699611745961}. Best is trial 40 with value: 0.9824561403508771.\n",
      "[I 2023-10-04 19:12:22,885] Trial 57 finished with value: 0.9736842105263158 and parameters: {'booster': 'gblinear', 'max_depth': 6, 'learning_rate': 0.2045694668060429, 'n_estimators': 98, 'subsample': 0.8470541037674647, 'colsample_bytree': 0.6684838436502736}. Best is trial 40 with value: 0.9824561403508771.\n",
      "[I 2023-10-04 19:12:33,557] Trial 58 finished with value: 0.9649122807017544 and parameters: {'booster': 'gblinear', 'max_depth': 8, 'learning_rate': 0.18725324185882897, 'n_estimators': 93, 'subsample': 0.8318327464928826, 'colsample_bytree': 0.6418232425844507}. Best is trial 40 with value: 0.9824561403508771.\n",
      "[I 2023-10-04 19:12:43,430] Trial 59 finished with value: 0.9649122807017544 and parameters: {'booster': 'gblinear', 'max_depth': 8, 'learning_rate': 0.17090232706337194, 'n_estimators': 89, 'subsample': 0.8689817762226402, 'colsample_bytree': 0.6786078283277748}. Best is trial 40 with value: 0.9824561403508771.\n",
      "[I 2023-10-04 19:12:46,377] Trial 60 finished with value: 0.6491228070175439 and parameters: {'booster': 'gblinear', 'max_depth': 7, 'learning_rate': 0.23783497596302394, 'n_estimators': 72, 'subsample': 0.8569073551838109, 'colsample_bytree': 0.6277980300658602}. Best is trial 40 with value: 0.9824561403508771.\n",
      "[I 2023-10-04 19:12:48,909] Trial 61 finished with value: 0.9736842105263158 and parameters: {'booster': 'gblinear', 'max_depth': 9, 'learning_rate': 0.19189839759071714, 'n_estimators': 100, 'subsample': 0.8835051433572697, 'colsample_bytree': 0.6456891189580847}. Best is trial 40 with value: 0.9824561403508771.\n",
      "[I 2023-10-04 19:12:49,220] Trial 62 finished with value: 0.37719298245614036 and parameters: {'booster': 'gblinear', 'max_depth': 8, 'learning_rate': 0.221615589095523, 'n_estimators': 96, 'subsample': 0.8784088138009735, 'colsample_bytree': 0.6353846219930921}. Best is trial 40 with value: 0.9824561403508771.\n",
      "[I 2023-10-04 19:12:49,485] Trial 63 finished with value: 0.9736842105263158 and parameters: {'booster': 'gblinear', 'max_depth': 8, 'learning_rate': 0.20565411133124537, 'n_estimators': 87, 'subsample': 0.8847538720464263, 'colsample_bytree': 0.6585848445035658}. Best is trial 40 with value: 0.9824561403508771.\n",
      "[I 2023-10-04 19:12:49,877] Trial 64 finished with value: 0.9736842105263158 and parameters: {'booster': 'gblinear', 'max_depth': 7, 'learning_rate': 0.19550338236722153, 'n_estimators': 82, 'subsample': 0.8901754031750918, 'colsample_bytree': 0.6140012547986182}. Best is trial 40 with value: 0.9824561403508771.\n",
      "[I 2023-10-04 19:12:50,612] Trial 65 finished with value: 0.9736842105263158 and parameters: {'booster': 'gblinear', 'max_depth': 8, 'learning_rate': 0.22869285406223624, 'n_estimators': 93, 'subsample': 0.8729310771242168, 'colsample_bytree': 0.6369366761185655}. Best is trial 40 with value: 0.9824561403508771.\n",
      "[I 2023-10-04 19:13:03,853] Trial 66 finished with value: 0.9736842105263158 and parameters: {'booster': 'gblinear', 'max_depth': 9, 'learning_rate': 0.2456940331003255, 'n_estimators': 100, 'subsample': 0.8617097958640134, 'colsample_bytree': 0.6022290017258625}. Best is trial 40 with value: 0.9824561403508771.\n",
      "[I 2023-10-04 19:13:10,344] Trial 67 finished with value: 0.9736842105263158 and parameters: {'booster': 'gblinear', 'max_depth': 7, 'learning_rate': 0.18726049240923595, 'n_estimators': 97, 'subsample': 0.8439696374712763, 'colsample_bytree': 0.6553147800877996}. Best is trial 40 with value: 0.9824561403508771.\n",
      "[I 2023-10-04 19:13:11,507] Trial 68 finished with value: 0.9649122807017544 and parameters: {'booster': 'gblinear', 'max_depth': 4, 'learning_rate': 0.1648702547272178, 'n_estimators': 91, 'subsample': 0.8322057222184387, 'colsample_bytree': 0.6439600397375281}. Best is trial 40 with value: 0.9824561403508771.\n",
      "[I 2023-10-04 19:13:12,416] Trial 69 finished with value: 0.9736842105263158 and parameters: {'booster': 'gblinear', 'max_depth': 8, 'learning_rate': 0.17717114669968886, 'n_estimators': 86, 'subsample': 0.8683369505360266, 'colsample_bytree': 0.7941210517799377}. Best is trial 40 with value: 0.9824561403508771.\n",
      "[I 2023-10-04 19:13:14,483] Trial 70 finished with value: 0.9473684210526315 and parameters: {'booster': 'gblinear', 'max_depth': 7, 'learning_rate': 0.2195103451290249, 'n_estimators': 41, 'subsample': 0.899855307506542, 'colsample_bytree': 0.6655026448171368}. Best is trial 40 with value: 0.9824561403508771.\n",
      "[I 2023-10-04 19:13:14,784] Trial 71 finished with value: 0.9736842105263158 and parameters: {'booster': 'gblinear', 'max_depth': 9, 'learning_rate': 0.18210301352034902, 'n_estimators': 95, 'subsample': 0.8810408125584135, 'colsample_bytree': 0.6613265036227969}. Best is trial 40 with value: 0.9824561403508771.\n",
      "[I 2023-10-04 19:13:26,283] Trial 72 finished with value: 0.9649122807017544 and parameters: {'booster': 'gblinear', 'max_depth': 9, 'learning_rate': 0.20593688678947153, 'n_estimators': 97, 'subsample': 0.888976117721095, 'colsample_bytree': 0.6550934786686675}. Best is trial 40 with value: 0.9824561403508771.\n",
      "[I 2023-10-04 19:13:30,445] Trial 73 finished with value: 0.9736842105263158 and parameters: {'booster': 'gblinear', 'max_depth': 10, 'learning_rate': 0.1984193611120283, 'n_estimators': 93, 'subsample': 0.877897802728468, 'colsample_bytree': 0.6808277413649753}. Best is trial 40 with value: 0.9824561403508771.\n",
      "[I 2023-10-04 19:13:34,631] Trial 74 finished with value: 0.956140350877193 and parameters: {'booster': 'gblinear', 'max_depth': 9, 'learning_rate': 0.18689708016720014, 'n_estimators': 50, 'subsample': 0.8538369146179194, 'colsample_bytree': 0.6695665390508315}. Best is trial 40 with value: 0.9824561403508771.\n",
      "[I 2023-10-04 19:13:34,710] Trial 75 finished with value: 0.9736842105263158 and parameters: {'booster': 'gblinear', 'max_depth': 8, 'learning_rate': 0.17085782970422017, 'n_estimators': 80, 'subsample': 0.865329303921728, 'colsample_bytree': 0.6239391674486595}. Best is trial 40 with value: 0.9824561403508771.\n",
      "[I 2023-10-04 19:13:47,243] Trial 76 finished with value: 0.9649122807017544 and parameters: {'booster': 'gblinear', 'max_depth': 9, 'learning_rate': 0.2127328711971378, 'n_estimators': 98, 'subsample': 0.8481183494100082, 'colsample_bytree': 0.6432891806550071}. Best is trial 40 with value: 0.9824561403508771.\n",
      "[I 2023-10-04 19:13:52,892] Trial 77 finished with value: 0.956140350877193 and parameters: {'booster': 'gblinear', 'max_depth': 6, 'learning_rate': 0.22867394631219498, 'n_estimators': 84, 'subsample': 0.8760200467260283, 'colsample_bytree': 0.660531920246519}. Best is trial 40 with value: 0.9824561403508771.\n",
      "[I 2023-10-04 19:13:54,108] Trial 78 finished with value: 0.9736842105263158 and parameters: {'booster': 'gblinear', 'max_depth': 8, 'learning_rate': 0.20877477550266732, 'n_estimators': 89, 'subsample': 0.8859737959095145, 'colsample_bytree': 0.6322818039622766}. Best is trial 40 with value: 0.9824561403508771.\n",
      "[I 2023-10-04 19:13:54,249] Trial 79 finished with value: 0.9473684210526315 and parameters: {'booster': 'gblinear', 'max_depth': 7, 'learning_rate': 0.15420578428527065, 'n_estimators': 47, 'subsample': 0.8580772899570469, 'colsample_bytree': 0.6819495582770271}. Best is trial 40 with value: 0.9824561403508771.\n",
      "[I 2023-10-04 19:13:55,233] Trial 80 finished with value: 0.9649122807017544 and parameters: {'booster': 'gbtree', 'max_depth': 8, 'learning_rate': 0.1958444252270377, 'n_estimators': 53, 'subsample': 0.8678525295330483, 'colsample_bytree': 0.6983922282337272}. Best is trial 40 with value: 0.9824561403508771.\n",
      "[I 2023-10-04 19:14:05,814] Trial 81 finished with value: 0.9649122807017544 and parameters: {'booster': 'gblinear', 'max_depth': 8, 'learning_rate': 0.20416097984629508, 'n_estimators': 75, 'subsample': 0.843239080472932, 'colsample_bytree': 0.7162455730795556}. Best is trial 40 with value: 0.9824561403508771.\n",
      "[I 2023-10-04 19:14:10,866] Trial 82 finished with value: 0.9649122807017544 and parameters: {'booster': 'gblinear', 'max_depth': 8, 'learning_rate': 0.18109433168276318, 'n_estimators': 77, 'subsample': 0.8405570384006965, 'colsample_bytree': 0.6715911830344354}. Best is trial 40 with value: 0.9824561403508771.\n",
      "[I 2023-10-04 19:14:11,991] Trial 83 finished with value: 0.9649122807017544 and parameters: {'booster': 'gblinear', 'max_depth': 7, 'learning_rate': 0.19886666559369862, 'n_estimators': 66, 'subsample': 0.8218806696784487, 'colsample_bytree': 0.6850740144697015}. Best is trial 40 with value: 0.9824561403508771.\n",
      "[I 2023-10-04 19:14:12,027] Trial 84 finished with value: 0.9649122807017544 and parameters: {'booster': 'gblinear', 'max_depth': 8, 'learning_rate': 0.21843580566122286, 'n_estimators': 60, 'subsample': 0.8511566530942443, 'colsample_bytree': 0.6988655933838929}. Best is trial 40 with value: 0.9824561403508771.\n",
      "[I 2023-10-04 19:14:13,473] Trial 85 finished with value: 0.9736842105263158 and parameters: {'booster': 'gblinear', 'max_depth': 9, 'learning_rate': 0.1916785492229147, 'n_estimators': 90, 'subsample': 0.8743597523121146, 'colsample_bytree': 0.6753998139779352}. Best is trial 40 with value: 0.9824561403508771.\n",
      "[I 2023-10-04 19:14:14,673] Trial 86 finished with value: 0.9473684210526315 and parameters: {'booster': 'gblinear', 'max_depth': 6, 'learning_rate': 0.1998276377449815, 'n_estimators': 35, 'subsample': 0.8926578901284804, 'colsample_bytree': 0.6536856982840697}. Best is trial 40 with value: 0.9824561403508771.\n",
      "[I 2023-10-04 19:14:34,845] Trial 87 finished with value: 0.9649122807017544 and parameters: {'booster': 'gbtree', 'max_depth': 7, 'learning_rate': 0.17365204693926262, 'n_estimators': 94, 'subsample': 0.856698727438974, 'colsample_bytree': 0.6643617517553085}. Best is trial 40 with value: 0.9824561403508771.\n",
      "[I 2023-10-04 19:14:43,641] Trial 88 finished with value: 0.9649122807017544 and parameters: {'booster': 'gblinear', 'max_depth': 8, 'learning_rate': 0.211387813483033, 'n_estimators': 77, 'subsample': 0.8376263962464803, 'colsample_bytree': 0.6856606612681476}. Best is trial 40 with value: 0.9824561403508771.\n",
      "[I 2023-10-04 19:15:39,800] Trial 89 finished with value: 0.9649122807017544 and parameters: {'booster': 'dart', 'max_depth': 10, 'learning_rate': 0.18224402196902276, 'n_estimators': 83, 'subsample': 0.8631075865357805, 'colsample_bytree': 0.7127127622493091}. Best is trial 40 with value: 0.9824561403508771.\n",
      "[I 2023-10-04 19:15:44,018] Trial 90 finished with value: 0.9736842105263158 and parameters: {'booster': 'gblinear', 'max_depth': 7, 'learning_rate': 0.18961367295233628, 'n_estimators': 87, 'subsample': 0.8823140603494324, 'colsample_bytree': 0.6490792526425889}. Best is trial 40 with value: 0.9824561403508771.\n",
      "[I 2023-10-04 19:15:46,039] Trial 91 finished with value: 0.9736842105263158 and parameters: {'booster': 'gblinear', 'max_depth': 6, 'learning_rate': 0.20679302221069965, 'n_estimators': 98, 'subsample': 0.8504188236483676, 'colsample_bytree': 0.6704374083916498}. Best is trial 40 with value: 0.9824561403508771.\n",
      "[I 2023-10-04 19:15:58,064] Trial 92 finished with value: 0.9736842105263158 and parameters: {'booster': 'gblinear', 'max_depth': 6, 'learning_rate': 0.2250492262335452, 'n_estimators': 100, 'subsample': 0.8712306312715297, 'colsample_bytree': 0.6649293875868076}. Best is trial 40 with value: 0.9824561403508771.\n",
      "[I 2023-10-04 19:16:07,386] Trial 93 finished with value: 0.9649122807017544 and parameters: {'booster': 'gblinear', 'max_depth': 5, 'learning_rate': 0.20032500249691204, 'n_estimators': 95, 'subsample': 0.8469389698511904, 'colsample_bytree': 0.6901924015077086}. Best is trial 40 with value: 0.9824561403508771.\n",
      "[I 2023-10-04 19:16:11,824] Trial 94 finished with value: 0.7456140350877193 and parameters: {'booster': 'gblinear', 'max_depth': 6, 'learning_rate': 0.21840685656680348, 'n_estimators': 92, 'subsample': 0.8628699588758673, 'colsample_bytree': 0.6782203410687652}. Best is trial 40 with value: 0.9824561403508771.\n",
      "[I 2023-10-04 19:16:24,113] Trial 95 finished with value: 0.9649122807017544 and parameters: {'booster': 'gblinear', 'max_depth': 7, 'learning_rate': 0.19276676948318847, 'n_estimators': 99, 'subsample': 0.8266493628195065, 'colsample_bytree': 0.6401862515961488}. Best is trial 40 with value: 0.9824561403508771.\n",
      "[I 2023-10-04 19:16:32,597] Trial 96 finished with value: 0.9649122807017544 and parameters: {'booster': 'gbtree', 'max_depth': 8, 'learning_rate': 0.23558998303793657, 'n_estimators': 96, 'subsample': 0.8381045122582134, 'colsample_bytree': 0.6678972462240518}. Best is trial 40 with value: 0.9824561403508771.\n",
      "[I 2023-10-04 19:16:44,557] Trial 97 finished with value: 0.9649122807017544 and parameters: {'booster': 'gblinear', 'max_depth': 7, 'learning_rate': 0.18479102232802685, 'n_estimators': 91, 'subsample': 0.8792592937615907, 'colsample_bytree': 0.6588669314540941}. Best is trial 40 with value: 0.9824561403508771.\n",
      "[I 2023-10-04 19:16:49,077] Trial 98 finished with value: 0.956140350877193 and parameters: {'booster': 'gblinear', 'max_depth': 6, 'learning_rate': 0.2099447864957692, 'n_estimators': 44, 'subsample': 0.8456029374091448, 'colsample_bytree': 0.650211095733305}. Best is trial 40 with value: 0.9824561403508771.\n",
      "[I 2023-10-04 19:16:56,887] Trial 99 finished with value: 0.9736842105263158 and parameters: {'booster': 'gblinear', 'max_depth': 8, 'learning_rate': 0.2026631474600113, 'n_estimators': 94, 'subsample': 0.8100240851873781, 'colsample_bytree': 0.6309167266943211}. Best is trial 40 with value: 0.9824561403508771.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:16:56] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"subsample\" } are not used.\n",
      "\n",
      "TBest Hyperparameters from Optuna:\n",
      "{'booster': 'gblinear', 'max_depth': 7, 'learning_rate': 0.2112313669279117, 'n_estimators': 91, 'subsample': 0.8484044756625635, 'colsample_bytree': 0.672932967850814}\n",
      "Best XGBoost Classifier Performance:\n",
      "Accuracy: 0.97\n",
      "Precision: 0.99\n",
      "Recall: 0.97\n",
      "F1-Score: 0.98\n",
      "ROC-AUC: 0.97\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "best_params = study.best_params\n",
    "best_model = xgb.XGBClassifier(**best_params)\n",
    "\n",
    "best_model.fit(X_train, y_train)\n",
    "y_pred = best_model.predict(X_test)\n",
    "best_accuracy = accuracy_score(y_test, y_pred)\n",
    "best_precision = precision_score(y_test, y_pred)\n",
    "best_recall = recall_score(y_test, y_pred)\n",
    "best_f1 = f1_score(y_test, y_pred)\n",
    "best_roc_auc = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "print(\"TBest Hyperparameters from Optuna:\")\n",
    "print(best_params)\n",
    "\n",
    "print(\"Best XGBoost Classifier Performance:\")\n",
    "print(f\"Accuracy: {best_accuracy:.2f}\")\n",
    "print(f\"Precision: {best_precision:.2f}\")\n",
    "print(f\"Recall: {best_recall:.2f}\")\n",
    "print(f\"F1-Score: {best_f1:.2f}\")\n",
    "print(f\"ROC-AUC: {best_roc_auc:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "universe",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
